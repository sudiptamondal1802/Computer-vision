{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the version of python\n",
    "from platform import python_version\n",
    "print(python_version())\n",
    "\n",
    "#pip install opencv \n",
    "#opencv-python has only the open cv version\n",
    "#opencv-contrib-python has both opencv version as well as any updates contributed by the community,\n",
    "#it includes all the required stuffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install caer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to read images\n",
    "import cv2 as cv\n",
    "\n",
    "#imread method takes the path to the image and returns the image the pixels\n",
    "img = cv.imread('23.jpg')\n",
    "\n",
    "#display the image, imshow displays the image as a window\n",
    "cv.imshow('Dog',img)\n",
    "#if we have large images it possible can go offscreen, which is why resizing might be needed\n",
    "\n",
    "#keyboard binding function, waits for delay for a key to be pressed, 0 waits for infinite amount of time\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to read videos\n",
    "import cv2 as cv\n",
    "\n",
    "#this function either takes in an integer as input or a path to a video file\n",
    "#integer 0 for webcam, 1 would first camera, 2 camera connected to computer and so on\n",
    "capture = cv.VideoCapture('/Users/sudiptamondal/Documents/QMUL/Project/Christmas_Celebration.mp4') #create an instance of the VideoCapture class\n",
    "\n",
    "#in video we use loop to read the video frame by frame\n",
    "while True:\n",
    "    #frame returns the frame, boolean isTrue says whether the frame was successfully read or not\n",
    "    isTrue, frame = capture.read()\n",
    "    \n",
    "    #display individual frame of the video\n",
    "    cv.imshow('Video',frame)\n",
    "    \n",
    "    #to stop the video from playing infinely\n",
    "    if cv.waitKey(20) & 0xFF==ord('d'):  #if the letter d is pressed then break out of the loop and stop displyaing the video\n",
    "        break\n",
    "capture.release()  \n",
    "cv.destroyAllWindows()\n",
    "\n",
    "#-215:Assertion failed error means that openCV could not find the image or the video in the \n",
    "#path specified or for video it ran out of frames, it could not be read in bascially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESIZES THE IMAGE TO A PARTICULAR SCALED DIMENSION\n",
    "#works for images, videos and live videos\n",
    "def rescaleFrame(frame, scale=0.25):\n",
    "    width  = int(frame.shape[1] * scale)\n",
    "    height = int(frame.shape[0] * scale)\n",
    "    dimensions = (width,height)\n",
    "    \n",
    "    return cv.resize(frame, dimensions, interpolation=cv.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For live videos for change the resolution and then rescaling frames\n",
    "#Change the resolution of the image of the video\n",
    "def changeRes(width,height):\n",
    "    #only works for live videos, this does not work on standalone video files\n",
    "    #3 is denotes the width for the capture.set class, similarly 4 denotes height, 10 denotes the brightness\n",
    "    capture.set(3,width) \n",
    "    capture.set(4,height)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "#Resizing and rescaling images and video frames \n",
    "#To prevent computational strain \n",
    "#Rescaling image means adjusting the images to a particular height and width\n",
    "#It is a best practice to downscale the values, as most camera do not support higher than its maximum capability\n",
    "\n",
    "#Resize for video\n",
    "capture = cv.VideoCapture('/Users/sudiptamondal/Documents/QMUL/Project/Christmas_Celebration.mp4') #create an instance of the VideoCapture class\n",
    "\n",
    "while True:\n",
    "    isTrue, frame = capture.read()\n",
    "    \n",
    "    frame_resized = rescaleFrame(frame)\n",
    "    #cv.imshow('Video', frame)\n",
    "    cv.imshow('Video', frame_resized)\n",
    "    \n",
    "    if cv.waitKey(20) & 0xFF==ord('d'):  \n",
    "        break\n",
    "capture.release()  \n",
    "cv.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resize for image\n",
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread('23.jpg')\n",
    "#cv.imshow('dog',img)\n",
    "\n",
    "resized_image = rescaleFrame(img)\n",
    "cv.imshow('resized_image', resized_image)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In jupyter notebook the cv.imshow hangs the kernel, therefore using matplotlib for the imshow\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "#DRAWING AND ADDING TEXT IN THE IMAGES\n",
    "#2 ways to draw on images:\n",
    "#1.  draw on the standalone image\n",
    "#2.  create a dummy blank image to work with\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "blank = np.zeros((500,500,3), dtype='uint8') #data type of an image is uint8\n",
    "\n",
    "#1. paint the image a certain colour\n",
    "#RGB\n",
    "#255,0,0 - RED\n",
    "#0,255,0 - GREEN\n",
    "#0,0,255 - BLUE\n",
    "#blank[:] = 0,0,255   #blank[:] - refeence all the pixels\n",
    "#blank[200:300, 300:400] = 0,0,255 #colout only certain pixels of the image\n",
    "\n",
    "#2. draw a rectangle\n",
    "#point1, point2, colour scale, thickness\n",
    "#thickness = integer value just creates a rectangle with a border, cv.FILLED or -1 fills out the shape\n",
    "#to fill in the rectangle\n",
    "#cv.rectangle(blank,(4,4),(300,300), (255,0,0),thickness = -1)\n",
    "cv.rectangle(blank,(4,4),(blank.shape[1]//5,blank.shape[0]//5), (255,0,0),thickness = -1)\n",
    "\n",
    "#3. draw a circle\n",
    "#the image, points of origin, radius, colour, thickness\n",
    "cv.circle(blank,(blank.shape[1]//5,blank.shape[0]//5),40,(0,0,255),thickness=-1)\n",
    "\n",
    "#4. draw a line\n",
    "cv.line(blank,(30,4), (blank.shape[1]//2,blank.shape[0]//2),(0,255,0),thickness=10)\n",
    "\n",
    "#write text on an image\n",
    "cv.putText(blank, 'Hello World', (2,225), cv.FONT_HERSHEY_TRIPLEX, 1.0, (0,255,0), thickness=2)\n",
    "\n",
    "plt.imshow(blank)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#The line above is necesary to show Matplotlib's plots inside a Jupyter Notebook\n",
    "#another way to run the opencv projects in pycharm or Spyter \n",
    "#is to exeucte the python code from the terminal instead of the console directly\n",
    "\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Import image\n",
    "image = cv.imread(\"23.jpg\")\n",
    "\n",
    "#Show the image with matplotlib\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "plt.imshow(gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "#5 ESSENTIAL FUNCTIONS IN OPENCV\n",
    "import cv2 as cv\n",
    "#1. converting an image to grayscale\n",
    "image = cv.imread(\"23.jpg\")\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "plt.imshow(gray)\n",
    "plt.show()\n",
    "\n",
    "#2. how to blur an image - extra elements due to bad lighting, reuce this noise by adding a slight blur\n",
    "#use a Gaussian blur\n",
    "#image, kernel size use on the image for blurring the image-it has to be an odd number\n",
    "#increase the kernel size to increase the bluriness\n",
    "blur = cv.GaussianBlur(image, (3,3), cv.BORDER_DEFAULT)\n",
    "plt.imshow(blur)\n",
    "plt.show()\n",
    "\n",
    "#3. edge cascade\n",
    "#find the edges that are present in the image\n",
    "#canny cascade is very popular in the computer vision world - it involves multistep process, gradient computation\n",
    "#canny = cv.Canny(image, 125, 175)\n",
    "canny = cv.Canny(blur, 125, 175) #to reduce some of the edges and keep the only some edges \n",
    "plt.imshow(canny)\n",
    "plt.show()\n",
    "\n",
    "#4. dilate the image using specific structure in the image\n",
    "#structure will be the edges\n",
    "dilated = cv.dilate(canny, (9,9), iterations=3) \n",
    "plt.imshow(dilated)\n",
    "plt.show()\n",
    "\n",
    "#5. eroding the dilated image to get back to the original structure, to get the edge cascade\n",
    "eroded = cv.erode(dilated, (9,9),iterations=3)\n",
    "plt.imshow(eroded)\n",
    "plt.show()\n",
    "\n",
    "#6. Resize\n",
    "#by default there is an interpolation that happens with interpolation= cv.INTER_AREA\n",
    "#this interpolation is useful if we are shrinakge the image that are smaller than that of the original image\n",
    "#use INTER_LINEAR or INTER_CUBIC when scaling to larger image than original (enlarging)\n",
    "#CUBIC is slowest among all but the resulting image has a much higher quality\n",
    "resized = cv.resize(image,(500,500))\n",
    "plt.imshow(resized)\n",
    "plt.show()\n",
    "\n",
    "#Cropping, array slicing\n",
    "cropped =image[50:200, 200:400]\n",
    "plt.imshow(cropped)\n",
    "plt.show()\n",
    "\n",
    "#cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#BASIC IMAGE TRANSFORMATION - translate/shift, rotate, resize, flip, crop\n",
    "import cv2 as cv\n",
    "image = cv.imread('23.jpg')\n",
    "\n",
    "#1. Translation - shifting an image along the x and y axis, up, down, left right\n",
    "#x and y refers to the number of pixels we would like to shift along the x and y axis\n",
    "def translate(img, x, y):\n",
    "    #create a translation matrix\n",
    "    transMat = np.float32([[1,0,x],[0,1,y]])\n",
    "    #image.shape[1] is width, and image.shape[0] is the height\n",
    "    dimensions = (image.shape[1], img.shape[0])\n",
    "    \n",
    "    return cv.warpAffine(image, transMat, dimensions)\n",
    "\n",
    "# -x --> left\n",
    "# -y --> up\n",
    "# +x --> right\n",
    "# +y --> down\n",
    "translated = translate(image, -100, -100)\n",
    "plt.imshow(translated)\n",
    "plt.show()\n",
    "\n",
    "#2. Rotation - specify any point to rotate around the centre, usually it is centre but it can be any arpbitraty point\n",
    "def rotate(image, angle, rotPoint=None):\n",
    "    (height,width) = image.shape[:2] #grab the height and width\n",
    "    \n",
    "    if rotPoint is None: #rotate around the centre\n",
    "        rotPoint = (width//2, height//2)\n",
    "        \n",
    "    #rotation matrix\n",
    "    #centre of rotation, angle, scale\n",
    "    rotMat = cv.getRotationMatrix2D(rotPoint, angle, 1.0)\n",
    "    dimensions = (width, height)\n",
    "    \n",
    "    return cv.warpAffine(image, rotMat, dimensions)\n",
    "\n",
    "rotated = rotate(image, -45)\n",
    "plt.imshow(rotated)\n",
    "plt.show()\n",
    "\n",
    "#black triangles get added on the images, and when we rotate further with rotate(image, -45) the black\n",
    "#portions rotate it as well, therefore, added the angles to -90 to avoide the skenewss\n",
    "rotated_rotated = rotate(image, -90)\n",
    "plt.imshow(rotated_rotated)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Resizing\n",
    "resized = cv.resize(image, (110,110), interpolation=cv.INTER_AREA)\n",
    "plt.imshow(resized)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. FLIPPING\n",
    "#0 - flipping the image vertically over the x-axis\n",
    "#1 - flipping the image horizontally over the y -axis\n",
    "#-1 - flipping the image both vertically as well as horizontally\n",
    "flipped = cv.flip(image, 1)\n",
    "plt.imshow(flipped)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Cropping\n",
    "cropped = image[200:400, 300:400]\n",
    "plt.imshow(cropped)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONTOUR DETECTION\n",
    "#contour are the boundaries of objects, the line or curve that joins the continuos boundaries of an object\n",
    "#not same as edge mathematically\n",
    "#useful when doing shape analysis, object detection and pattern recognition\n",
    "\n",
    "#convert the image to grayscale\n",
    "grey = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "#structure/edges the image\n",
    "canny = cv.Canny(image, 125, 175) \n",
    "\n",
    "#blur = cv.GaussianBlur(gray,(5,5),cv.BORDER_DEFAULT) #reduces the number of controus to aignificant amount\n",
    "#canny = cv.Canny(blur, 125, 175)\n",
    "\n",
    "#countours looks at the structure of the element and returns 2 values\n",
    "#parameters to findContours is the struture of the image found by canny, mode, \n",
    "#contour apprximation method - how we want to approximate the contours,. CHAIN_APPROX_NONE  does nothing\n",
    "#CHAIN_APPROX_SIMPLE compresses all the controus to a simple representation, for example if we have a line in an image\n",
    "# we will get all the coordinates of the line, CHAIN_APPROX_SIMPLE will approximate to just 2 points\n",
    "#modes - RETR_TREE - to get all the hierarchies of the contours\n",
    "#RETR_EXTERNAL - only the external contours\n",
    "#RETR_LIST - get all the contours\n",
    "contours, hierarchies = cv.findContours(canny, cv.RETR_LIST, cv.CHAIN_APPROX_NONE)\n",
    "#countours - python list of all the coordinates of the countours\n",
    "#hierarchies - refers to the hierarchichal representations of the countours - \n",
    "#rectangle -contains sqaure, sqaure contains circle etc.\n",
    "print(f'{len(contours)} contour(s) found')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contour using threshold instead of canny, another way for contouring\n",
    "ret, threshold = cv.threshold(canny, 125, 255, cv.THRESH_BINARY)\n",
    "plt.imshow(threshold)\n",
    "plt.show()\n",
    "#threshold tries to look into an image and then binarize that image\n",
    "#if the intensity y of the pix below 125 set to while, else set to black\n",
    "contours, hierarchies = cv.findContours(threshold, cv.RETR_LIST, cv.CHAIN_APPROX_NONE)\n",
    "print(f'{len(contours)} contour(s) found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DRAW COUNTOURS ON A BLANK IMAGE\n",
    "import numpy as np\n",
    "blank = np.zeros(image.shape, dtype = 'uint8') #same dimension as original image\n",
    "cv.drawContours(blank, contours, -1, (0,0,255), 2)\n",
    "plt.imshow(blank)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERAL PRACTICE:\n",
    "#use canny first, and then contours on it rather than threshold the image and then contour\n",
    "#becuase we binarize the values in threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COLOUR SPACES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#space of colours - a system to represent an array of pixels of colours, RGB, GRAY, HSV, LAB, and many more\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt #the image format is RGB and in open cv it is BGR and hence inversion of coulor\n",
    "\n",
    "img = cv.imread('23.jpg')\n",
    "cv.imshow('Dog',img)\n",
    "\n",
    "#BGR to RGB\n",
    "rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "cv.imshow('RGB', rgb)\n",
    "\n",
    "plt.imshow(rgb)\n",
    "plt.show()\n",
    "\n",
    "#BGR to GRAY (distribution of pixel intensity at particular image)\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('Gray', gray)\n",
    "\n",
    "#BGR to HSV (Hue, Saturation, value) - based on how humans percieve the notion of colour\n",
    "hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "cv.imshow('HSV',hsv)\n",
    "\n",
    "#BGR to LAB\n",
    "lab = cv.cvtColor(img, cv.COLOR_BGR2LAB)\n",
    "cv.imshow('LAB', lab)\n",
    "\n",
    "#outside of opencv we use RGB format so inversion of colour\n",
    "\n",
    "cv.waitKey(0)\n",
    "\n",
    "#NOTES:\n",
    "#We cannot convert grayscal image to HSV, in order to do that we need to convert BGR to grayscale and then BGR2HSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COLOR CHANNELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#there are essentially 3 channels -RGB/bgr, opencv allows the to split the image into colour channels\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread('23.jpg')\n",
    "rgb = cv.cvtColor(img,cv.COLOR_BGR2RGB)\n",
    "plt.imshow(rgb)\n",
    "plt.show()\n",
    "\n",
    "b,g,r = cv.split(rgb)\n",
    "plt.imshow(b,cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(g,cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(r,cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(rgb.shape)\n",
    "print(b.shape)\n",
    "print(g.shape)\n",
    "print(r.shape)\n",
    "\n",
    "#region dark - no pixels in the region, lighter region more intensity of the pixels\n",
    "#gray scale shows the distribution of the pixels, grayscal image have shape of 1\n",
    "merged = cv.merge([b,g,r])\n",
    "plt.imshow(merged)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconstruct images with the inidvidual channels\n",
    "blank = np.zeros(img.shape[:2],dtype='uint8') #blank consists of the height and width only without color channels\n",
    "red = cv.merge([r,blank,blank])  #only setting blue and rest components as blacks\n",
    "green = cv.merge([blank,g,blank])\n",
    "blue = cv.merge([blank,blank,b])\n",
    "\n",
    "plt.imshow(red)\n",
    "#lighter portions high distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLURRING TECHNIQUES\n",
    "- We smooth images when there are lot of noise and the noise can  be because of the camera sensors, the ligting. We aim blur the image to smooth the noise\n",
    "\n",
    "- Kernel/Filter/Window: draw over a specific portion of the image with number of rows and columns. Blur is applied to the center of the kernel as a result of the surrounding pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import cv2 as cv\n",
    "img = cv.imread('23.jpg')\n",
    "rgb = cv.cvtColor(img,cv.COLOR_BGR2RGB)\n",
    "plt.imshow(rgb)\n",
    "plt.show()\n",
    "\n",
    "#1. AVERAGING - computing the centre of the kernel as the average of the surrounding pixel intensities\n",
    "#slide the window and then do the same thing for the whole image\n",
    "#higher the kernel size more the blur\n",
    "average = cv.blur(rgb,(9,9))\n",
    "\n",
    "#2. GAUSSIAN BLUR - each surrounding pixel is given a weight and the weighted average is calculated\n",
    "#less blur than averaging but more natural\n",
    "#the 3rd parameter here is the standard deviation\n",
    "gauss = cv.GaussianBlur(rgb,(9,9),0)\n",
    "\n",
    "#3. MEDIAN BLUR - same as averaging except that instead of finding average of the surrounding pixels\n",
    "#the median is calculated. This method is more effective in removing noise and used in advanced CV projects\n",
    "#good in removing the salt and pepper noises\n",
    "#opencv assumes that the kernel size is 3 x 3 based on the interger 3\n",
    "median = cv.medianBlur(rgb,3)\n",
    "\n",
    "#BILATERAL BLUR - traditional blurring methods blur the image without looking at edges and the corners being affected\n",
    "# This method applies the blurring and retaining the edges and the corners\n",
    "# 3rd parameter - larger values of sigmacolor indicates that more colours will be considered while blurring the image\n",
    "# 2nd parameter - diameter\n",
    "# 4th parameter - sigma space - larger values indicate that the pixels further out will influence the blurring\n",
    "bilateral = cv.bilateralFilter(rgb, 15, 35, 25)\n",
    "\n",
    "plt.imshow(bilateral)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BITWISE OPERATIONS\n",
    "Operate in binary manner\n",
    "- AND\n",
    "- OR\n",
    "- XOR\n",
    "- NOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import cv2 as cv\n",
    "\n",
    "blank = np.zeros((400,400),dtype='uint8')\n",
    "#draw rectangle\n",
    "rectangle = cv.rectangle(blank.copy(), (30,30), (370,370), 255, thickness=-1)\n",
    "plt.imshow(rectangle,cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "#draw circle\n",
    "circle = cv.circle(blank.copy(),(200,200),200,255,-1)\n",
    "plt.imshow(circle,cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "#bitwise AND - returns the intersection of the images\n",
    "bitwise_AND = cv.bitwise_and(rectangle,circle)\n",
    "plt.imshow(bitwise_AND,cmap='gray')\n",
    "\n",
    "#bitwise OR - returns the union of the images\n",
    "bitwise_OR = cv.bitwise_or(rectangle,circle)\n",
    "plt.imshow(bitwise_OR,cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "#bitwise XOR - returns the NOT OR of the images, non-intersecting regions or the two images\n",
    "bitwise_XOR = cv.bitwise_xor(rectangle,circle)\n",
    "plt.imshow(bitwise_XOR,cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "#bitwise NOT - inverts the binary colours and takes just one source image\n",
    "bitwise_NOT = cv.bitwise_not(circle)\n",
    "plt.imshow(bitwise_NOT,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MASKING\n",
    "- Using the bitwaise operators masking can be performed on the images\n",
    "- masking lets us focus on certain images, so if we want to focus only on faces of people, we can mask the faces and remove the rest from the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import cv2 as cv\n",
    "img = cv.imread('23.jpg')\n",
    "rgb = cv.cvtColor(img,cv.COLOR_BGR2RGB)\n",
    "\n",
    "#NOTE: Dimension of the mask has to be same as that of the image, else it will not work\n",
    "blank = np.zeros(rgb.shape[:2],dtype='uint8')\n",
    "#circle as a mask - image, centre, radius, colour, thikcness\n",
    "#mask = cv.circle(blank,(rgb.shape[1]//2 + 45,rgb.shape[0]//2 + 45), 100, 255, thickness=-1)\n",
    "\n",
    "#rectangle as a mask - image, length, breadth, colour, thickness\n",
    "mask = cv.rectangle(blank,(rgb.shape[1]//2,rgb.shape[0]//2), (rgb.shape[1]//2 + 100,rgb.shape[0]//2 + 100), 255, thickness=-1)\n",
    "plt.imshow(mask,cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "#apply masking on the image\n",
    "masked_image = cv.bitwise_and(rgb,rgb,mask=mask)\n",
    "plt.imshow(masked_image,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMPUTING HISTOGRAMS\n",
    "- Histograms allows to visualise pixel intensities in an image\n",
    "- it helps to analyse the pixel intensities and might also be useful if we want to have equal amount of intensities for the images instead of peaking intensities, histograms helps in this visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import cv2 as cv\n",
    "img = cv.imread('23.jpg')\n",
    "rgb = cv.cvtColor(img,cv.COLOR_BGR2RGB)\n",
    "\n",
    "blank = np.zeros(rgb.shape[:2],dtype='uint8')\n",
    "gray = cv.cvtColor(rgb,cv.COLOR_RGB2GRAY)\n",
    "\n",
    "#mask for grayscale\n",
    "circle = cv.circle(blank,(rgb.shape[1]//2 + 45,rgb.shape[0]//2 + 45), 100, 255, thickness=-1)\n",
    "mask = cv.bitwise_and(gray,gray,mask=circle)\n",
    "#grayscale histogram - pass list of images, number of channels for which we want the histogram for,\n",
    "#provide a mask if you wanrt to build the histogram for a specific portion of the image\n",
    "#number of bins\n",
    "#range of all possible pixel values\n",
    "\n",
    "gray_hist = cv.calcHist([gray], [0], mask, [256], [0,256])\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Grayscale Histogram masked')\n",
    "plt.xlabel('Bins')  #intervals of pixel intensities\n",
    "plt.ylabel('# of pixels')\n",
    "plt.plot(gray_hist)\n",
    "plt.xlim([0,256]) #limit the x-axis\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#mask for coloured image\n",
    "mask = cv.circle(blank,(rgb.shape[1]//2 + 45,rgb.shape[0]//2 + 45), 100, 255, thickness=-1)\n",
    "masked = cv.bitwise_and(rgb,rgb,mask=mask)\n",
    "\n",
    "#colour histogram\n",
    "plt.figure()\n",
    "plt.title('Colour Histogram masked')\n",
    "plt.xlabel('Bins')  #intervals of pixel intensities\n",
    "plt.ylabel('# of pixels')\n",
    "colors = ('b','g','r')\n",
    "for i,col in enumerate(colors):  #i is the channel, col is the colour\n",
    "          hist = cv.calcHist([rgb],[i],mask, [256], [0,256])\n",
    "          plt.plot(hist, color=col)\n",
    "          plt.xlim([0,256])\n",
    "              \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THRESHOLDING\n",
    "- Binarization of image, we have an image and we want to convert it to a binary image, pixels are either 0 or 255\n",
    "- a simple way to implement this is to have a threshold value and if the pixel value is less than the threshold value make that pixel intensity to 0 else 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import cv2 as cv\n",
    "img = cv.imread('23.jpg')\n",
    "rgb = cv.cvtColor(img,cv.COLOR_BGR2RGB)\n",
    "gray =cv.cvtColor(rgb, cv.COLOR_RGB2GRAY)\n",
    "plt.imshow(gray,cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "#1. SIMPLE THRESHOLDING - looks at the image,compares each pixel value to the threshold value and assigns binary pixel\n",
    "#threshold = 150\n",
    "#thresh = binarized image\n",
    "\"\"\"\n",
    "threshold, thresh = cv.threshold(gray, 170, maxval=255, type=cv.THRESH_BINARY)\n",
    "plt.imshow(thresh,cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "#inverse thresholded image\n",
    "threshold, thresh_inverse = cv.threshold(gray, 170, maxval=255, type=cv.THRESH_BINARY_INV)\n",
    "plt.imshow(thresh_inverse,cmap='gray')\n",
    "plt.show()\n",
    "\"\"\"\n",
    "#2. ADAPTIVE THRESHOLDING - in the simple thresholding we need to specify the threshold manually, which might\n",
    "#work in some cases but not in all scenarios. We could let the computer find the optimal threshold by itself\n",
    "#and then binarize the image\n",
    "\n",
    "#Source image, maxValue, adaptive method - that tells the computer which method to use when computing the \n",
    "#optimum value for threshold - ADAPTIVE_THRESH_MEAN_C. ADAPTIVE_THRESH_GAUSSIAN_C\n",
    "#threshold type -THRESH_BINARY_INV, THRESH_BINARY\n",
    "#blocksize - neighbourhod size of the kernel size which opencv needs to compute the mean, kernel size 11 x 11\n",
    "#c value - integer subtracted from the mean, allowing us to fine tune the threshold\n",
    "adaptive_thresh = cv.adaptiveThreshold(gray, 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY,11,5)\n",
    "plt.imshow(adaptive_thresh,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDGE DETECTION / GRADIENTS\n",
    "\n",
    "Algorithms\n",
    "1. CANNY\n",
    "2. LAPLACIAN\n",
    "3. SOBEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import cv2 as cv\n",
    "img = cv.imread('23.jpg')\n",
    "rgb = cv.cvtColor(img,cv.COLOR_BGR2RGB)\n",
    "gray =cv.cvtColor(rgb, cv.COLOR_RGB2GRAY)\n",
    "plt.imshow(gray,cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "#1. LAPLACIAN  -computes the gradient of the image\n",
    "#source image, data depth??\n",
    "#black to white +ve slope, white to black -ve slope\n",
    "#images cannot have negative pixel values, compute the absolute values and then convert to uint8(image specific data type)\n",
    "lap = cv.Laplacian(gray, cv.CV_64F)\n",
    "lap = np.uint8(np.absolute(lap))\n",
    "plt.imshow(lap,cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "#2. SOBEL - computes gradient in x and y direction\n",
    "sobelx = cv.Sobel(gray, cv.CV_64F, 1, 0)  #gradient computed along x-axis\n",
    "sobely = cv.Sobel(gray, cv.CV_64F, 0, 1)  #gradient computed along y-axis\n",
    "combined_sobel = cv.bitwise_or(sobelx, sobely)\n",
    "\n",
    "#3. CANNY - advanced algorithm - multistage process and one of the stage does use sobel\n",
    "canny = cv.Canny(gray, 150, 175)\n",
    "\n",
    "plt.imshow(canny,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FACE DETECTION\n",
    "\n",
    "#### DETECTION: identifying the face from images, done using classifier, whether a face is present or not.\n",
    "Clasifiers need to be trained with lot of faced. Opencv does have pre-trained classifier.\n",
    "\n",
    "- Harcascade classifier: look at the object in an image and then use the edges to detect whether the object is a face or not. Popular but not effective. Not suitable for advanced CV\n",
    "- Local binary pattern classifer\n",
    "\n",
    "#### RECOGNITION: identifying whose face it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import cv2 as cv\n",
    "img = cv.imread('multiple-face.jpg')\n",
    "rgb = cv.cvtColor(img,cv.COLOR_BGR2RGB)\n",
    "gray = cv.cvtColor(rgb,cv.COLOR_RGB2GRAY)\n",
    "\n",
    "#read the harcasecade.xml\n",
    "haar_cascade = cv.CascadeClassifier('haar_face.xml')\n",
    "\n",
    "#detect the face in the image\n",
    "#minNeighbours - number of neighbours the rectangle has to capture to call the object a face\n",
    "#to reduce the noise so that the classification is good, increase the scale fatcor and the minimum neighbours\n",
    "faces_rect = haar_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=11)\n",
    "\n",
    "print(f'Number of faces found = {len(faces_rect)}')\n",
    "\n",
    "#faces_rect is a list of rectangular coordinates of the faces that are present, therefore we can loop through the\n",
    "#coordinates to draw a rectangle on the face detected\n",
    "for (x,y,w,h) in faces_rect:\n",
    "    cv.rectangle(rgb, (x,y) , (x+w,y+h),(0,255,0),thickness=2)\n",
    "\n",
    "plt.imshow(rgb)\n",
    "plt.show()\n",
    "\n",
    "#for using the face detection in a video, the haarcascade classifier needs to be applied on every frame of the video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FACE RECOGNITION USING OPENCV BUILT-IN FACE RECOGNIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "#create the list of people you want to recognize\n",
    "people = []\n",
    "#loop over every folder to build the list dynamically\n",
    "DIR = r'/Users/sudiptamondal/Documents/QMUL/Project/OpenCV tutorial/Faces/Train'\n",
    "\n",
    "#read the harcasecade.xml\n",
    "haar_cascade = cv.CascadeClassifier('haar_face.xml')\n",
    "\n",
    "for f in os.listdir(DIR):\n",
    "    if not f.startswith('.'):\n",
    "        people.append(f)\n",
    "\n",
    "#CREATE THE TRAINING DATASET\n",
    "#loop over every folder in the base folder, and inside the folder loop over every image \n",
    "#and grap the face on the images and add to the training set\n",
    "#training set consists of two lists for features and labels\n",
    "features = [] #image array of faces\n",
    "labels   = []   #whose face is it\n",
    "\n",
    "def create_train():\n",
    "    for person in people:\n",
    "        path = os.path.join(DIR, person)  #path to the image folder for the person\n",
    "        label = people.index(person)\n",
    "\n",
    "        for image in os.listdir(path):    #for each image in the person folder\n",
    "            if not image.startswith('.'):\n",
    "                img_path = os.path.join(path,image)\n",
    "                img_array = cv.imread(img_path)\n",
    "                gray = cv.cvtColor(img_array, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "                #detect the faces in the image\n",
    "                faces_rect = haar_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10)\n",
    "\n",
    "                for (x,y,w,h) in faces_rect:\n",
    "                    #face region of interest, crop the face in the image\n",
    "                    faces_roi = gray[y:y+h, x:x+w]\n",
    "                    features.append(faces_roi)\n",
    "                    #the reason for converting the label to a numerical value of index is to reduce the computational strain\n",
    "                    #by creating a mapping between the image and the label\n",
    "                    labels.append(label)\n",
    "\n",
    "create_train()\n",
    "#print(f'Length of the features = {len(features)}')\n",
    "#print(f'Length of the labels = {len(labels)}')\n",
    "features = np.array(features, dtype='object')\n",
    "labels = np.array(labels)\n",
    "print('Training dataset creation done.........')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an instance of the opencv face recognizer\n",
    "face_recognizer = cv.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "#Train the Recognizer on the features list and the labels list\n",
    "face_recognizer.train(features, labels)\n",
    "\n",
    "#save the trained model\n",
    "face_recognizer.save('face_trained.yml')\n",
    "\n",
    "np.save('features.npy',features)\n",
    "np.save('labels.npy',labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the saved trained model for face recognition\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "people = []\n",
    "#loop over every folder to build the list dynamically\n",
    "DIR = r'/Users/sudiptamondal/Documents/QMUL/Project/OpenCV tutorial/Faces/Train'\n",
    "\n",
    "#read the harcasecade.xml\n",
    "haar_cascade = cv.CascadeClassifier('haar_face.xml')\n",
    "\n",
    "for f in os.listdir(DIR):\n",
    "    if not f.startswith('.'):\n",
    "        people.append(f)\n",
    "\n",
    "features = np.load('features.npy',allow_pickle=True)\n",
    "labels = np.load('labels.npy',allow_pickle=True)\n",
    "\n",
    "face_recognizer = cv.face.LBPHFaceRecognizer_create()\n",
    "#read the yml file which has the trained model saved\n",
    "face_recognizer.read('face_trained.yml')\n",
    "\n",
    "valdir = r'/Users/sudiptamondal/Documents/QMUL/Project/OpenCV tutorial/Faces/Val/unseen.jpeg'\n",
    "img = cv.imread(valdir)\n",
    "gray_val = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('Person', gray_val)\n",
    "\n",
    "#detect the face in the unseen image\n",
    "faces_rect = haar_cascade.detectMultiScale(gray_val, 1.1, 4)\n",
    "\n",
    "#crop the image, draw a rectangle around the unseen image and add a text in the image\n",
    "for (x,y,w,h) in faces_rect:\n",
    "    faces_roi = gray_val[y:y+h, x:x+w]\n",
    "    \n",
    "    label, confidence = face_recognizer.predict(faces_roi)\n",
    "    print(f'Label = {people[label]} with a confidence of {confidence}')\n",
    "    \n",
    "    cv.putText(img, str(people[label]), (20,20), cv.FONT_HERSHEY_COMPLEX, 1.0, (0,255,0), thickness=2)\n",
    "    cv.rectangle(img,(x,y),(x+w,y+h),(0,255,0),thickness=2)\n",
    "\n",
    "cv.imshow('Detected Face', img)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEEP COMPUTER VISION\n",
    "- we need deep learning when the number of images is large and the number of classes are big as well\n",
    "- opencv is used for preprocessing of the data when doing deep learning like normalization, mean subtraction \n",
    "- GPUs help in faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting canaro\n",
      "  Downloading canaro-1.1.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: tensorflow in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from canaro) (2.3.1)\n",
      "Requirement already satisfied: caer in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from canaro) (1.9.8)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->canaro) (3.14.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->canaro) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->canaro) (2.3.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->canaro) (3.3.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->canaro) (1.33.2)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->canaro) (1.6.3)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->canaro) (0.34.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->canaro) (1.15.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->canaro) (0.3.3)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->canaro) (2.4.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->canaro) (2.10.0)\n",
      "Collecting numpy<1.19.0,>=1.16.0\n",
      "  Downloading numpy-1.18.5-cp38-cp38-macosx_10_9_x86_64.whl (15.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.1 MB 7.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->canaro) (0.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->canaro) (1.11.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->canaro) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->canaro) (1.1.0)\n",
      "Requirement already satisfied: opencv-contrib-python in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from caer->canaro) (4.5.1.48)\n",
      "Requirement already satisfied: typing-extensions in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from caer->canaro) (3.7.4.2)\n",
      "Requirement already satisfied: mypy in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from caer->canaro) (0.800)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow->canaro) (3.3.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow->canaro) (1.7.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow->canaro) (2.24.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow->canaro) (49.2.0.post20200714)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow->canaro) (0.4.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow->canaro) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow->canaro) (1.23.0)\n",
      "Requirement already satisfied: mypy-extensions<0.5.0,>=0.4.3 in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from mypy->caer->canaro) (0.4.3)\n",
      "Requirement already satisfied: typed-ast<1.5.0,>=1.4.0 in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from mypy->caer->canaro) (1.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->canaro) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->canaro) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->canaro) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->canaro) (2.10)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->canaro) (1.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->canaro) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->canaro) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->canaro) (4.1.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->canaro) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/sudiptamondal/opt/anaconda3/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->canaro) (0.4.8)\n",
      "Installing collected packages: canaro, numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.4\n",
      "    Uninstalling numpy-1.19.4:\n",
      "      Successfully uninstalled numpy-1.19.4\n",
      "Successfully installed canaro-1.1.0 numpy-1.18.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install canaro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
